{
  "certificate": {
    "id": "2023-006",
    "url": "https://codecheck.org.uk/register/certs/2023-006/"
  },
  "paper": {
    "title": "Semantic complexity of geographic questions - A comparison in terms of conceptual transformations of answers",
    "authors": [
      {
        "name": "Enkhbold Nyamsuren"
      },
      {
        "name": "Haiqi Xu"
      },
      {
        "name": "Eric J. Top"
      },
      {
        "name": "Simon Scheider"
      },
      {
        "name": "Niels Steenbergen"
      }
    ],
    "reference": "https://doi.org/10.5194/agile-giss-4-10-2023",
    "abstract": {
      "text": "<jats:p>Abstract. There is an increasing trend of applying AIbased automated methods to geoscience problems. An important example is a geographic question answering (geoQA) focused on answer generation via GIS workflows rather than retrieval of a factual answer. However, a representative question corpus is necessary for developing, testing, and validating such generative geoQA systems. We compare five manually constructed geographical question corpora, GeoAnQu, Giki, GeoCLEF, GeoQuestions201, and Geoquery, by applying a conceptual transformation parser. The parser infers geo-analytical concepts and their transformations from a geographical question, akin to an abstract GIS workflow. Transformations thus represent the complexity of geo-analytical operations necessary to answer a question. By estimating the variety of concepts and the number of transformations for each corpus, the five corpora can be compared on the level of geo-analytical complexity, which cannot be done with purely NLP-based methods. Results indicate that the questions in GeoAnQu, which were compiled from GIS literature, require a higher number as well as more diverse geo-analytical operations than questions from the four other corpora. Furthermore, constructing a corpus with a sufficient representation (including GIS) may require an approach targeting a uniquely qualified group of users as a source. In contrast, sampling questions from large-scale online repositories like Google, Microsoft, and Yahoo may not provide the quality necessary for testing generative geoQA systems. \n                    <\/jats:p>",
      "source": "CrossRef"
    }
  },
  "codecheck": {
    "codecheckers": [
      {
        "name": "Philipp A. Friese",
        "orcid": "0000-0002-3124-5364"
      },
      {
        "name": "Jakub Krukar",
        "orcid": "0000-0003-2615-8757"
      }
    ],
    "check_time": "2023-06-13 12:00:00",
    "repository": "osf::d2shf",
    "report": "https://doi.org/10.17605/OSF.IO/D2SHF",
    "type": "conference",
    "venue": "AGILEGIS",
    "summary": "The data and software of the paper under reproduction is published on GitHub under an MIT license.\nAll figures, tables, and embedded data points have been reproduced.\nThe authors showed dedication and concern to support reproducibility of their work.\nReproduction was successful.\n",
    "manifest": [
      {
        "file": "NA",
        "comment": "The AGILE 2023 Reproducibility Review did not include manifest documentation, see https://github.com/codecheckers/register/issues/49"
      }
    ]
  }
}
